{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mIJd6b6pbsk"
      },
      "source": [
        "# First, let us set up a few dependencies\n",
        "\n",
        "Don't forget to switch to a GPU-enabled colab runtime!\n",
        "\n",
        "```\n",
        "Runtime -> Change Runtime Type -> GPU\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6E2APl4pnbAa"
      },
      "source": [
        "import os\n",
        "import contextlib\n",
        "@contextlib.contextmanager\n",
        "def directory(name):\n",
        "  ret = os.getcwd()\n",
        "  os.chdir(name)\n",
        "  yield None\n",
        "  os.chdir(ret)\n",
        "\n",
        "import subprocess\n",
        "def run(input, exception_on_failure=False):\n",
        "  try:\n",
        "    program_output = subprocess.check_output(f\"{input}\", shell=True, universal_newlines=True, stderr=subprocess.STDOUT)\n",
        "  except Exception as e:\n",
        "    if exception_on_failure:\n",
        "      raise e\n",
        "    program_output = e.output\n",
        "\n",
        "    return program_output\n",
        "def prun(input, exception_on_failure=False):\n",
        "  x = run(input, exception_on_failure)\n",
        "  print(x)\n",
        "  return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6gJLjcipgNw"
      },
      "source": [
        "# This mounts your google drive to this notebook. You might have to change the path to fit with your dataset folder inside your drive.\n",
        "\n",
        "Read the instruction output by the cell bellow carefully!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a temporary workspace\n",
        "import tempfile\n",
        "\n",
        "\n",
        "SESSION_WORKSPACE = tempfile.mkdtemp()\n",
        "print(f\"Session workspace created at: {SESSION_WORKSPACE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shRmyOAbatwZ",
        "outputId": "e84b0ba8-f06b-46b1-efef-6237fe4c2ac2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session workspace created at: /tmp/tmp0xdxo_jl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "DRIVE_PATH = \"/content/drive/My Drive\""
      ],
      "metadata": {
        "id": "Iod0c4KF_Vxo",
        "outputId": "5aadb5b3-3515-41a5-fc8f-efbd4b26f8cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the dataset\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "\n",
        "DATASET_DIR_NAME = \"duckietown_object_detection_dataset\"\n",
        "DATASET_ZIP_NAME = f\"{DATASET_DIR_NAME}.zip\"\n",
        "DATASET_DIR_PATH = os.path.join(SESSION_WORKSPACE, DATASET_DIR_NAME)\n",
        "TRAIN_DIR = \"train\"\n",
        "VALIDATION_DIR = \"val\"\n",
        "IMAGES_DIR = \"images\"\n",
        "LABELS_DIR = \"labels\"\n",
        "\n",
        "\n",
        "def show_info(base_path: str):\n",
        "  for l1 in [TRAIN_DIR, VALIDATION_DIR]:\n",
        "    for l2 in [IMAGES_DIR, LABELS_DIR]:\n",
        "      p = os.path.join(base_path, l1, l2)\n",
        "      print(f\"#Files in {l1}/{l2}: {len(os.listdir(p))}\")\n",
        "\n",
        "\n",
        "def unzip_dataset():\n",
        "  # check zipped file\n",
        "  zip_path = os.path.join(DRIVE_PATH, DATASET_ZIP_NAME)\n",
        "  assert os.path.exists(zip_path), f\"No zipped dataset found at {zip_path}! Abort!\"\n",
        "\n",
        "  # unzip the data\n",
        "  print(\"Unpacking zipped data...\")\n",
        "  shutil.unpack_archive(zip_path, DATASET_DIR_PATH)\n",
        "  print(f\"Zipped dataset unpacked to {DATASET_DIR_PATH}\")\n",
        "\n",
        "  # show some info\n",
        "  show_info(DATASET_DIR_PATH)\n",
        "\n",
        "\n",
        "unzip_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhdlb1osbf_a",
        "outputId": "a0b19a74-0365-48e5-dd1c-24344aaae645"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unpacking zipped data...\n",
            "Zipped dataset unpacked to /tmp/tmp0xdxo_jl/duckietown_object_detection_dataset\n",
            "#Files in train/images: 1604\n",
            "#Files in train/labels: 1604\n",
            "#Files in val/images: 402\n",
            "#Files in val/labels: 402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change  working directory to the session workspace\n",
        "os.chdir(SESSION_WORKSPACE)\n",
        "print(f\"PWD: {os.getcwd()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpWozMbUeFZA",
        "outputId": "7d0c3ec7-8158-4a0f-8698-332f796f20b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PWD: /tmp/tmp0xdxo_jl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc4VMcwmpr84"
      },
      "source": [
        "# Next, we will clone Yolov5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8L68QAeZF9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9111d65-1f8c-4bee-db55-866a54f98ae0"
      },
      "source": [
        "!rm -rf ./yolov5\n",
        "!git clone https://github.com/duckietown/yolov5.git -b dt-obj-det\n",
        "#!git clone https://github.com/ultralytics/yolov5.git -b v7.0\n",
        "!cd yolov5 && pip3 install -r requirements.txt\n",
        "!pip3 install torch==1.7.0 torchvision==0.8.1"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 6174, done.\u001b[K\n",
            "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 6174 (delta 5), reused 0 (delta 0), pack-reused 6163\u001b[K\n",
            "Receiving objects: 100% (6174/6174), 8.44 MiB | 12.16 MiB/s, done.\n",
            "Resolving deltas: 100% (4215/4215), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 5)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (6.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (1.7.3)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (1.7.0)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (0.8.1)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (4.64.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 15)) (2.9.1)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 19)) (0.11.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 20)) (1.3.5)\n",
            "Requirement already satisfied: thop in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 28)) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pycocotools>=2.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 29)) (2.0.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->-r requirements.txt (line 10)) (4.4.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (57.4.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.51.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.6)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.19.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.6.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->-r requirements.txt (line 20)) (2022.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 15)) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.4.1->-r requirements.txt (line 15)) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 15)) (3.2.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.7.0 in /usr/local/lib/python3.8/dist-packages (1.7.0)\n",
            "Requirement already satisfied: torchvision==0.8.1 in /usr/local/lib/python3.8/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.7.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.7.0) (4.4.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.8/dist-packages (from torch==1.7.0) (0.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from torch==1.7.0) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.8.1) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We can now inform the training process of the format and location of our dataset"
      ],
      "metadata": {
        "id": "g5iilV-e76YN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile ./yolov5/data/duckietown.yaml\n",
        "\n",
        "# train and val data as 1) directory: path/images/, 2) file: path/images.txt, or 3) list: [path1/images/, path2/images/]\n",
        "train: ../duckietown_object_detection_dataset/train\n",
        "val: ../duckietown_object_detection_dataset/val\n",
        "\n",
        "# number of classes\n",
        "nc: 4\n",
        "\n",
        "# class names\n",
        "names: [ 'duckie', 'cone', 'truck', 'bus' ]"
      ],
      "metadata": {
        "id": "7u3D124u8Flw",
        "outputId": "54b4a3ba-c4a7-4388-f9ec-1f930222310f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting ./yolov5/data/duckietown.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CalmQI9Ypx5v"
      },
      "source": [
        "# And we're ready to train! This step will take about 5 minutes.\n",
        "\n",
        "Notice that we're only training for 10 epochs. That's probably not enough!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kss7Oid6OkAv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb8cb0ca-6fba-4a73-846b-1a47fbe1011e"
      },
      "source": [
        "!cd yolov5 && git pull && python3 train.py --cfg ./models/yolov5n.yaml --img 416 --batch 64 --epochs 1 --data duckietown.yaml --weights yolov5s.pt"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/duckietown/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v5.0-71-g0343bc7 torch 1.7.0 CPU\n",
            "\n",
            "Namespace(adam=False, artifact_alias='latest', batch_size=64, bbox_interval=-1, bucket='', cache_images=False, cfg='./models/yolov5n.yaml', data='./data/duckietown.yaml', device='', entity=None, epochs=1, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[416, 416], label_smoothing=0.0, linear_lr=False, local_rank=-1, multi_scale=False, name='exp', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/exp', save_period=-1, single_cls=False, sync_bn=False, total_batch_size=64, upload_dataset=False, weights='yolov5s.pt', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mtensorboard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 104MB/s] \n",
            "\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              \n",
            "  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
            "  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
            "  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  4                -1  1     29184  models.common.C3                        [64, 64, 2]                   \n",
            "  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  6                -1  1    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n",
            "  9                -1  1    164608  models.common.SPP                       [256, 256, [5, 9, 13]]        \n",
            " 10                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 11                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 12                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 13           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 14                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 15                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            " 16                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 17           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 18                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
            " 19                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
            " 20          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 21                -1  1     82688  models.common.C3                        [192, 128, 1, False]          \n",
            " 22                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 23          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 24                -1  1    329216  models.common.C3                        [384, 256, 1, False]          \n",
            " 25      [17, 20, 23]  1     19089  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 192, 384]]\n",
            "Model Summary: 296 layers, 2113649 parameters, 2113649 gradients, 4.6 GFLOPS\n",
            "\n",
            "Transferred 34/380 items from yolov5s.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 65 .bias, 65 conv.weight, 62 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../duckietown_object_detection_dataset/train/labels' images and labels... 1604 found, 0 missing, 171 empty, 0 corrupted: 100% 1604/1604 [00:00<00:00, 3015.13it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../duckietown_object_detection_dataset/train/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '../duckietown_object_detection_dataset/val/labels' images and labels... 402 found, 0 missing, 37 empty, 0 corrupted: 100% 402/402 [00:00<00:00, 1373.19it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: ../duckietown_object_detection_dataset/val/labels.cache\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 4.62, Best Possible Recall (BPR) = 0.9638. Attempting to improve anchors, please wait...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mWARNING: Extremely small objects found. 149 of 3622 labels are < 3 pixels in size.\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mRunning kmeans for 9 anchors on 3596 points...\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9801 best possible recall, 5.56 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.364/0.772-mean/best, past_thr=0.502-mean: 6,8,  14,17,  20,25,  27,39,  54,26,  40,59,  109,60,  68,101,  173,129\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mEvolving anchors with Genetic Algorithm: fitness = 0.7839: 100% 1000/1000 [00:01<00:00, 639.88it/s]\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mthr=0.25: 0.9801 best possible recall, 5.82 anchors past thr\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mn=9, img_size=416, metric_all=0.381/0.781-mean/best, past_thr=0.511-mean: 8,11,  14,17,  19,23,  26,35,  57,21,  37,50,  60,77,  106,56,  165,123\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mNew anchors saved to model. Update model *.yaml to use these anchors in the future.\n",
            "\n",
            "Image sizes 416 train, 416 test\n",
            "Using 2 dataloader workers\n",
            "Logging results to runs/train/exp\n",
            "Starting training for 1 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total    labels  img_size\n",
            "       0/0        0G    0.1185   0.02156   0.04261    0.1827        21       416: 100% 26/26 [07:46<00:00, 17.95s/it]\n",
            "               Class      Images      Labels           P           R      mAP@.5  mAP@.5:.95: 100% 4/4 [00:46<00:00, 11.72s/it]\n",
            "                 all         402         936    0.000247      0.0587    6.45e-05    1.04e-05\n",
            "              duckie         402         565    0.000317      0.0442    2.23e-05    3.84e-06\n",
            "                cone         402         157           0           0           0           0\n",
            "               truck         402          67           0           0           0           0\n",
            "                 bus         402         147     0.00067        0.19    0.000236    3.77e-05\n",
            "1 epochs completed in 0.144 hours.\n",
            "\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 4.4MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 4.4MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "all_exps = os.listdir(\"yolov5/runs/train\")\n",
        "all_exps_filtered = map(lambda x: int(x.replace(\"exp\", \"1\")), filter(lambda x: x.startswith(\"exp\"), all_exps))\n",
        "all_exps_filtered = np.array(list(all_exps))\n",
        "latest_exp_index = np.argmax(all_exps)\n",
        "latest_exp = all_exps[latest_exp_index]\n",
        "# print(f\"Latest exp is {latest_exp}\")\n",
        "\n",
        "prun(f\"cp yolov5/runs/train/{latest_exp}/weights/best.pt yolov5/best.pt\")\n",
        "print(f\"Marked the model from the latest run ({latest_exp}) as yolov5/best.pt.\")"
      ],
      "metadata": {
        "id": "b5jSQ4XubFqH",
        "outputId": "7c8e267d-e18a-4c2c-f762-e519d4a490b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Marked the model from the latest run (exp) as yolov5/best.pt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz2PZ7d0qPt0"
      },
      "source": [
        "# Next, we can upload your model to Duckietown's cloud!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bNXEgAFpRIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17f82d5-7072-4f46-bed6-dc924ce57590"
      },
      "source": [
        "!pip3 install git+https://github.com/duckietown/lib-dt-mooc@mooc2022"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/duckietown/lib-dt-mooc@mooc2022\n",
            "  Cloning https://github.com/duckietown/lib-dt-mooc (to revision mooc2022) to /tmp/pip-req-build-9kece66r\n",
            "  Running command git clone -q https://github.com/duckietown/lib-dt-mooc /tmp/pip-req-build-9kece66r\n",
            "  Running command git checkout -b mooc2022 --track origin/mooc2022\n",
            "  Switched to a new branch 'mooc2022'\n",
            "  Branch 'mooc2022' set up to track remote branch 'mooc2022' from 'origin'.\n",
            "Collecting dt-data-api-daffy>=0.1.8\n",
            "  Downloading dt-data-api-daffy-1.1.3.tar.gz (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from dt-data-api-daffy>=0.1.8->dt-mooc==0.0.5) (2.23.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from dt-data-api-daffy>=0.1.8->dt-mooc==0.0.5) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from dt-data-api-daffy>=0.1.8->dt-mooc==0.0.5) (4.9.1)\n",
            "Collecting dt-authentication-daffy\n",
            "  Downloading dt-authentication-daffy-0.1.16.tar.gz (3.3 kB)\n",
            "Collecting base58\n",
            "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
            "Collecting ecdsa\n",
            "  Downloading ecdsa-0.18.0-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 142 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from ecdsa->dt-authentication-daffy->dt-data-api-daffy>=0.1.8->dt-mooc==0.0.5) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->dt-data-api-daffy>=0.1.8->dt-mooc==0.0.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->dt-data-api-daffy>=0.1.8->dt-mooc==0.0.5) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->dt-data-api-daffy>=0.1.8->dt-mooc==0.0.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->dt-data-api-daffy>=0.1.8->dt-mooc==0.0.5) (2.10)\n",
            "Building wheels for collected packages: dt-mooc, dt-data-api-daffy, dt-authentication-daffy\n",
            "  Building wheel for dt-mooc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dt-mooc: filename=dt_mooc-0.0.5-py3-none-any.whl size=6489 sha256=6d6af220265565e2de07106753a43dd8924e8fa618da63b233c66fb4e6968ff4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ggzwfhet/wheels/7a/2e/72/79fb182d351314e4d6fb9aff8bdd01c1610c981db999440152\n",
            "  Building wheel for dt-data-api-daffy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dt-data-api-daffy: filename=dt_data_api_daffy-1.1.3-py3-none-any.whl size=13714 sha256=0c25cff3bde96ab7a0645d8250007dc6f1e2bc8524c9d0876f5ee93ea9199560\n",
            "  Stored in directory: /root/.cache/pip/wheels/38/ce/fb/5a988e5766d210a7586879219893e14a85ebca9f179ee91041\n",
            "  Building wheel for dt-authentication-daffy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dt-authentication-daffy: filename=dt_authentication_daffy-0.1.16-py3-none-any.whl size=3432 sha256=7cf511450d484c300ea7c0c27cb15b03a000ad570f56543ccaacd65367789760\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/a0/1c/f2cfd43e7989e84af4ddc942406e6716c5aaf98cddcda8da54\n",
            "Successfully built dt-mooc dt-data-api-daffy dt-authentication-daffy\n",
            "Installing collected packages: ecdsa, base58, dt-authentication-daffy, dt-data-api-daffy, dt-mooc\n",
            "Successfully installed base58-2.1.1 dt-authentication-daffy-0.1.16 dt-data-api-daffy-1.1.3 dt-mooc-0.0.5 ecdsa-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fill in the duckietown token here\n",
        "YOUR_DT_TOKEN = \"dt1-daZUHiuSz7CV52v4YS9wpXWsgnVtPyMP4sFd39x53WeZa-43dzqWFnWd8KBa1yev1g3UKnzVxZkkTbfiQFRKqBYf6sPsgu6ELuBXhtVPzwZJqnAm\""
      ],
      "metadata": {
        "id": "hl-HhnrFtKnp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dt_mooc.cloud import Storage\n",
        "from dt_mooc.utils import select_device\n",
        "import sys\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.insert(0, './yolov5')\n",
        "\n",
        "destination_name = \"yolov5mnfp32\"\n",
        "best = torch.load(\"./yolov5/best.pt\", map_location=select_device(\"cpu\"))\n",
        "pt_model = best['model']\n",
        "pt_weights_path = \"./yolov5/best.pt\"\n",
        "storage = Storage(YOUR_DT_TOKEN)\n",
        "\n",
        "\n",
        "# convert to fp32\n",
        "device = select_device('cpu')\n",
        "pt_model = pt_model.to(device).float()  # load to FP32\n",
        "pt_model.eval()\n",
        "\n",
        "best['model'] = pt_model\n",
        "\n",
        "# save to disk\n",
        "pt_weights_path = os.path.join(os.path.dirname(pt_weights_path), f\"{destination_name}.pt\")\n",
        "torch.save(best, pt_weights_path)\n",
        "print(pt_weights_path)\n",
        "\n",
        "# compute hash\n",
        "storage.hash(pt_weights_path)\n",
        "hash_path = pt_weights_path+\".sha256\"\n",
        "\n",
        "# UPLOAD .pt\n",
        "storage._upload(destination_name, [pt_weights_path, hash_path])"
      ],
      "metadata": {
        "id": "oMs3Ea_41hQb",
        "outputId": "3c2a12c9-8313-4c68-8d90-b8dfd699b7f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <progress\n",
              "                value='100'\n",
              "                max='100',\n",
              "                style='width: 100%'\n",
              "            >\n",
              "                100\n",
              "            </progress>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./yolov5/yolov5mnfp32.pt\n",
            "Uploading file `yolov5mnfp32.pt`...\n",
            "\n",
            "File `yolov5mnfp32.pt` successfully uploaded! It will now be found at `courses/mooc/objdet/data/nn_models/yolov5mnfp32.pt`.\n",
            "Uploading file `yolov5mnfp32.pt.sha256`...\n",
            "\n",
            "File `yolov5mnfp32.pt.sha256` successfully uploaded! It will now be found at `courses/mooc/objdet/data/nn_models/yolov5mnfp32.sha256`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dt_mooc.cloud import Storage\n",
        "from dt_mooc.utils import select_device\n",
        "import sys\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "sys.path.insert(0, './yolov5')\n",
        "\n",
        "destination_name = \"yolov5hf\"\n",
        "best = torch.load(\"./yolov5/best.pt\", map_location=select_device(\"cpu\"))\n",
        "pt_model = best['model']\n",
        "pt_weights_path = \"./yolov5/best.pt\"\n",
        "storage = Storage(YOUR_DT_TOKEN)\n",
        "\n",
        "\n",
        "# convert to fp16\n",
        "device = select_device('cpu')\n",
        "pt_model = pt_model.to(device).half()  # load to FP16\n",
        "pt_model.eval()\n",
        "\n",
        "best['model'] = pt_model\n",
        "\n",
        "# save to disk\n",
        "pt_weights_path = os.path.join(os.path.dirname(pt_weights_path), f\"{destination_name}.pt\")\n",
        "torch.save(best, pt_weights_path)\n",
        "print(pt_weights_path)\n",
        "\n",
        "# compute hash\n",
        "storage.hash(pt_weights_path)\n",
        "hash_path = pt_weights_path+\".sha256\"\n",
        "\n",
        "# UPLOAD .pt\n",
        "storage._upload(destination_name, [pt_weights_path, hash_path])"
      ],
      "metadata": {
        "id": "o7jJqBP60lbT",
        "outputId": "b8cf4172-3180-4089-925a-e959832eb793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./yolov5/yolov5hf.pt\n",
            "Uploading file `yolov5hf.pt`...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <progress\n",
              "                value='100'\n",
              "                max='100',\n",
              "                style='width: 100%'\n",
              "            >\n",
              "                100\n",
              "            </progress>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File `yolov5hf.pt` successfully uploaded! It will now be found at `courses/mooc/objdet/data/nn_models/yolov5hf.pt`.\n",
            "Uploading file `yolov5hf.pt.sha256`...\n",
            "\n",
            "File `yolov5hf.pt.sha256` successfully uploaded! It will now be found at `courses/mooc/objdet/data/nn_models/yolov5hf.sha256`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3HWb4wMpZc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "0364630a-8ec1-4c4c-f06a-9fe30de41784"
      },
      "source": [
        "from dt_mooc.cloud import Storage\n",
        "from dt_mooc.utils import select_device\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "storage = Storage(YOUR_DT_TOKEN)\n",
        "\n",
        "storage.upload_yolov5_only(\"yolov5\", model, \"./yolov5/best.pt\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading file `best.pt`...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <progress\n",
              "                value='100'\n",
              "                max='100',\n",
              "                style='width: 100%'\n",
              "            >\n",
              "                100\n",
              "            </progress>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File `best.pt` successfully uploaded! It will now be found at `courses/mooc/objdet/data/nn_models/yolov5.pt`.\n",
            "Uploading file `best.pt.sha256`...\n",
            "\n",
            "File `best.pt.sha256` successfully uploaded! It will now be found at `courses/mooc/objdet/data/nn_models/yolov5.sha256`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUVJ5BfBGq7F"
      },
      "source": [
        "# Done!\n",
        "\n",
        "We're done training! You can now close this tab and go back to the `Training` notebook"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rNd8aBq9Zc2l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}